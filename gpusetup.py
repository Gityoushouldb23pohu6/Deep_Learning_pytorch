# -*- coding: utf-8 -*-
"""gpusetup

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yRuhp2ftlNBjdZFqWzz4sXNqJrsqtE17

## #.Putting tensors andd models in the gpu

The reason we want our tensors/models on the gpu because using gpu reults in faster computations
"""

import torch



#setup device agnostic code
device = 'cuda' if torch.cuda.is_available() else 'cpu'
device

torch.cuda.device_count()

tensor=torch.tensor([1,2,3])
print(tensor,tensor.device)  # tensor not on gpu

#move tensor to GPU (if available)

tensor_on_gpu = tensor.to(device)
tensor_on_gpu

#### numpy mostly works on the cpu

# moving tensors back to CPU

#if tensor is on gpu , can't transform it to numpy

tensor_on_gpu.numpy()

#To fix the gpu tensor with numpy issue, we can first set it ot the cpu
tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()
tensor_back_on_cpu

tensor_on_gpu # remains unchanged