# -*- coding: utf-8 -*-
"""pytorch_workflow

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TYnk4QZH-j6UAAsSfRqcr6BPe_K1ktNG
"""

what_were_covering = {
    1:'data(prepare and load)',
    2: 'build model',
    3: 'fitting the model to data (training )',
    4: 'making predictions and evaluating a model(inference)',
    5: 'saving and loading a model',

    6: 'putting it all together',


}

import torch
from torch import nn
import matplotlib.pyplot as plt


torch.__version__

"""Data :
data can be almost anything in machine learning .

*excel spreadsheet
* images of any kind
* Videos (youtube has a lots of data )
* audio like songs or podcasts
* DNA
* Text


Machine learning is a game of two parts :

* Get data into a numerical representation.
* Build a model to learn patterns in that numerical representation .


To showcase this , let's create some known data using the linear regression formula .

We'll use a linear regressor formula to make a straight line with known **parameters**


"""

# Create *known* parameters

weight = 0.7   # can take any random value
bias =0.3


start= 0
end = 1

step = 0.02

X=torch.arange(start , end , step ).unsqueeze(dim=1)  # we need the unsqueezing part

y=weight * X + bias

X[:10] ,y[:10]

len(X),len(y)

"""# Splitting the data into training and testing sets (most important in ml )



let's create a training and testing set
"""

#Create a train_test split

train_split = int(0.8 * len(X))
X_train,y_train = X[:train_split],y[:train_split]
X_test ,y_test =X[train_split:],y[train_split:]

len(X_train),len(y_train),len(X_test),len(y_test)

X_train,y_train

def plot_predictions(train_data = X_train,train_labels=y_train
                     ,test_data= X_test ,
                     test_labels=y_test,
                     predictions=None):

  plt.figure(figsize=(10,7))

  # plt the training data in blue
  plt.scatter(train_data,train_labels,c='b',s=4,label='Training data ')


  # plot test data in green

  plt.scatter(test_data,test_labels,c='g',s=4,label='testing data')
  # are there predictions ?
  if predictions is not None :
    plt.scatter(test_data,predictions,c='r',label='predictions' )

  plt.legend(prop = {'size': 14});

plot_predictions();

"""**BUILDING A MODEL  :**    




What our model does :

* Start with random values ((weight and bias )

* look at the training data and adjust the values to better represent(or get closer ) to the ideal values (the weight and bias values we used to create the data )

How does it do so ?

Through two main algorithms :     

1) Gradient descent
2) Back propogation
"""

#Building model
from torch import nn #-> neural network


# creating linear regression model class


#every models we are building in pytorch must be subclasses of nn.Module


class LinearRegressionModel(nn.Module): # <-almost eveything in pytorch is inherited from nn.Module
  def __init__(self):

    super().__init__()

    self.weights=nn.Parameter(torch.randn(1,# <= start with a random weight and try to adjust it to the ideal weight

                                          requires_grad=True,   # here our model uses gradient (it answers the question whether this parameter be updated via gradient descent ? )
                                          dtype=torch.float))
    self.bias = nn.Parameter(torch.randn(1,  #<=- start with a random bias and try to adjust it to the ideal weight
                                         requires_grad=True,  # gradient descent (can this parameter be updated via gradient descent ?)
                                         dtype=torch.float)) # pytorch's ideal datatype ->float32


    #any subclass of nn.Module needs to override the forward method to define the computaion in the model

  def forward (self, x: torch.Tensor) -> torch.tensor : #x is the input data
       return self.weights * x + self.bias # linear regression formula



# our model uses the graident of weight and the gradient of bias along with the backpropogation to make the necesseary adjustments in the parameters

"""### PyTorch model building essentials

* torch.nn - contatins all the buildings for computational graphs (a neural network can be considered a computational graph )
*torch.nn.Parameter - what parameters should our model try and learn , often a PyTorch layers from torch.nn will set these for us

* torch.nn.module -> The base class for all neural network modules , if you subclass it , you should override forward()
* torch.optim -> this where the optimisers in pytorch live , they will help with gradient descent (better optimise the parameters to represent our dataset )

* def forward() -- All nn.Module subclass requires you to override the forward() method , this method defined what happens in the forward computation .

## Checking different contennts of our PyTorch models

Now weve created a model , let's see whats inside
So we can check our model parameters or what's inside our model using .parameters()
"""

#Create a random seed (because of all the random functions we have created inside our model class)



torch.manual_seed(42)

#create an instance of the model (subclass of nn.Module )
model_0 = LinearRegressionModel()
#check our the parameters
list (model_0.parameters())

#List named parameters
model_0.state_dict()

weight ,bias # we will have our aim to make the above values as close to the below values as possible

"""## Making prediction using torch.inference_mode()

To check our model's predictive power , let's see how well it predicts y_test based on X_test

When we pass data through our model , its going to run it through our forward() method
"""

# Make predictions (inference_mode is preferred above any else )

with torch.inference_mode():   # another name for inference is predictions
  y_preds = model_0(X_test)

y_preds

''' here the inference_mode()  turns of all the helpful trackings  during training (like gradient tracking )
    that is because it reduces the time of computations and gives faster results .
'''


# or do this

#with torch.no_grad():
 # y_preds = model_0(X_test)
  #y_preds


#if in case you are getting a not implemented error CHECK THE INDENTATIONS IN THE CLASS

y_pred = model_0(X_test)
y_pred                    # exactly same , but not recommended to use right now

y_test,y_preds

plot_predictions(predictions=y_preds )

"""## Train model

The whole idea of training is for a model to move from some *unknown * paramters to some known parameters

In other works poor representation of the data to a better representation of data


One way to measure how poor or how wrong your models predictions are is to use a loss funcion .


* Note -> loss /cost /criterion all the same thing


Things we need to train :

**Loss function :**

A function to measure how wrong your model's prediction are to the ideal outputs , lower is better

**Optimiser:**

takes into account the loss of a model and adjusts the model's parameters (eg. weight and bias )
to improve the loss function .


Specifically for PyTorch ::
we need :     
* Training loop
* Testing loop





"""

list(model_0.parameters()) # if you are geiing a generator in the output better to use a list

# Check our our model's parameters (parameter is value that the model sets itself )
model_0.state_dict()

#Setup a loss function

loss_fn= nn.L1Loss()  # MAE mean absolute error
loss_fn
# setup an optmiser

# stochastic gradient descent -> stocastic means random , gradients
loss_fn = nn.L1Loss()

# Setup an optimiser(stochastic gradient descent)
optimiser = torch.optim.SGD(params = model_0.parameters(),
                            lr=0.01) # lr= learning rate (possibly most important hyperparameter )
# The more the learning rate , the faster/larger the parameters are changed internelly

# our optimiser esentially lowers the loss function value till an extend where it further can't be reduced

"""## BUILDING A TRAINING AND TESTING LOOP :

A couple of things we need in a training loop :
0. Loop through the data
1. Forward pass (this involves data moving through our model's forward() functions ) - also called forward propogation
2. Calculate the loss (compare forward pass predictions to ground truth labels)
3. Optimiser zero grad
4. Loss backward - moves backward through the network to calculate the gradients of each of the
                 parameters of our model with repect to the loss ->  **backpropogation**
5.Optimiser step - the optimiser to adjust our model's parameters to try and improve the loss ->  **graident descent**                  


**visualise**
                 
let's say we want to get down a top of a hill , now at any point during the down journey we have some non zero gradient .
and when we reach the bottom , the gradient is 0 and the slope there is 0 .
                 
and that is exactly how we make the loss function value 0 .
                 


"""

# An epoch is one loop through the data ...(this is a hyperparameter because we've set them ourselves )


epochs = 200

# Track different values

epoch_count=[]
loss_values=[]
test_loss_values= []



## Training



# 0 .Loop through data

for epoch in range(epochs) :

  # Set the model to training mode
  model_0.train() # train mode in PyTorch set all parameters that set
  # 1 . Forward pass
  y_pred = model_0(X_train)


  # 2 . calculate the loss

  loss= loss_fn(y_pred,y_train)
  # print(f'Loss : {loss}')
  # Optimiser zero grad
  optimiser.zero_grad() # making the change to be converting to 0

  # Perform backpropogation on the loss with respect to the parameter s of the model
  loss.backward()

  # 5. Step the optimiser (perform gradient descent)
  optimiser.step() # by default how the optimiser changes will accumulate through the loop so.. we have to zero them above in step 3 for the next iteration of the loop .


## Testing

  model_0.eval() # turns off different setings in the model not needed for evaluations (batchnorm / dropout))

  with torch.inference_mode(): # turns off gradient tracking  and couple more things
  # with torch.no_grad_()  or torch.no_grad()

    #1. Do the forward pass in testing mode

    test_pred = model_0(X_test)

    # calculate the loss

    test_loss = loss_fn(test_pred,y_test)

    # Print out what's happening

  if epoch %10 == 0 :
    epoch_count.append(epoch)
    loss_values.append(loss)
    test_loss_values.append(test_loss)

    print(f'Epoch : {epoch} | Loss  : {loss} | Test_loss : {test_loss }')

  #print our model state_dict()
    print(model_0.state_dict())

with torch.inference_mode():
  y_pred_new = model_0(X_test)

print(y_pred_new)

model_0.state_dict()

weight, bias

plot_predictions(predictions=y_pred_new)
# now we are going to keep rerunning till we dont align the red points with green ones

epoch_count,loss_values,test_loss_values

import numpy as np

np.array(torch.tensor(loss_values).numpy()) , test_loss_values  # we can't plot unless we convert it to numpy

#Plot the loss curves

plt.plot(epoch_count,np.array(torch.tensor(loss_values).numpy()),label='Train Loss')
plt.plot(epoch_count,test_loss_values,label='Test loss')
plt.title('Training and testing loss curves ')
plt.ylabel('loss')
plt.xlabel('Epochs')
plt.legend();


# matplot lib works with numpy so , we can't have pytorch datasets

# if the training and the testing loss curves are far away and don't converge at somepoint , then we have a problem

"""

##Saving a model in Pytorch

There are three main methods your should about for saving and loading models in Pytorch .

1. torch.save() - allows you to save a PyTorch object in Python's pickle format
2. torch.load() - allows you to load a saved PyTorch object .

3. torch.nn.Module.load_state_dict() -  this allows to load a model's save state dictionary"""

model_0.state_dict()

"""# we want to save our model just in case we want to use it in a different notebook .
# either state_dict or save/load the entire model .


"""

from pathlib import Path
# used for writing file paths

# 1. Create a models directory

MODEL_PATH = Path('models')
MODEL_PATH.mkdir(parents =True, exist_ok = True)  # mkdir - make directory


#2. Create a model save path

MODEL_NAME = '01_pytorch_workflow_model_0.pth'  # .pth is the saving extension of files for pytorch
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME   # PATH LIKE OBJECT


MODEL_SAVE_PATH

# 3. Save the model state dict (recommended way )

print(f'saving model to : {MODEL_SAVE_PATH}')
torch.save(obj = model_0.state_dict(),f = MODEL_SAVE_PATH)

!ls -l models

"""## Loading a PyTorch Model

Since we moved our model's state_dict() rather the entire model , we'll create a new instance of our model class and load the saved state_dict() into that
"""

model_0.state_dict()

#To load in a saved state_dict we have to instantiate a new instance of our model class

loaded_model_0 = LinearRegressionModel()


# Load the saved state_dict of model_0(this will update the new isntance with updated parameters )

loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))

loaded_model_0.state_dict()

# Make some predictions with our loaded model

loaded_model_0.eval()

with torch.inference_mode():
  loaded_model_preds = loaded_model_0(X_test)
loaded_model_preds

#Make some models preds

model_0.eval()
with torch.inference_mode():
  y_preds = model_0(X_test)

y_preds

y_preds == loaded_model_preds

"""### PUTTING IT ALL TOGETHER

Let's go  through the steps above and see it all in one place

"""

device







